# RAG 101: Building Your Own Personal Retrieval Augmented Generation Model

**Prerequisites:**
- **Python Skills:** Basic understanding of Python programming.
- **Jupyter Notebook/Google Colab Experience:** Familiarity with Jupyter Notebook or Google Colab environments.
- **OpenAI API Key:** Access to your own OpenAI API key for model interactions.

### Concepts Covered
In this tutorial, we will explore the following key areas of RAG:
- **Text Splitting and Chunking:** Learn how to prepare and process text data for efficient retrieval.
- **Vector Embeddings:** Understand the role of vector embeddings in representing text data for semantic search.
- **Semantic Search:** Discover how to implement semantic search to find the most relevant text chunks for query answering.
- **LLM (Large Language Model) Answer Generation and Evaluation:** Explore how to generate answers using a large language model and evaluate their relevance and accuracy.
- **Gradio WebUI:** Get hands-on experience building a simple web interface with Gradio to interact with your RAG model.

## Getting Started

### Step-by-Step Instructions

1. **Launch the Colab Notebook:**
   - Access the Colab Notebook by clicking on the following link: [RAG 101 Colab Notebook](https://colab.research.google.com/drive/1LUpKKqa6Bgt1U7HPA3hvyhZJBLn5uXPZ?usp=sharing).
   - This notebook contains all the code and detailed instructions needed to build your RAG model.

2. **Set Up Your Environment:**
   - Once in Colab, ensure that your runtime is set to use a GPU (e.g., Tesla T4) for optimal performance. This is crucial for handling the computational demands of model training and inference.

### Additional Resources

- **Presentation Slides:**
  For a comprehensive overview of the concepts and processes involved in this project, refer to the accompanying slides: [RAG 101 Slides](https://docs.google.com/presentation/d/1SFUPAIX3fGeBvaiPoLbNarNpWci9y4TSgNzZO-tnVOk/edit?usp=sharing).

### This README was written by GPT4
